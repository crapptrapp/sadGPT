{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crapptrapp/sadGPT/blob/main/sadGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using https://github.com/agrechnev/hugging_examples/blob/master/train_gpt2_torch1.py"
      ],
      "metadata": {
        "id": "GJoDiPWOgk8s"
      },
      "id": "GJoDiPWOgk8s"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": 2.7299665331067346e+38,
        "outputId": "41023bb0-0039-4115-df12-e09d3fe20ef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-w_lxb8jc\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-w_lxb8jc\n",
            "  Resolved https://github.com/huggingface/transformers to commit a6e6b1c622d8d08e2510a82cb6266d7b654f1cbf\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.8-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0.dev0) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers==4.32.0.dev0)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0.dev0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0.dev0) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.32.0.dev0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers==4.32.0.dev0)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.32.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.6)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.29.2-py2.py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.6/215.6 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Collecting accelerate>=0.20.3 (from transformers==4.32.0.dev0)\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.32.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.32.0.dev0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.32.0.dev0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.32.0.dev0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.32.0.dev0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: transformers, pathtools\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.32.0.dev0-py3-none-any.whl size=7445483 sha256=919c5b06330e1aa0a7a1fdbe819d1de4cdf4c0de120809b1c834f82ebe2b1597\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rlvlcsni/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=ca64703778ff803fe1fbaee26b334881a45a9535be3b0a7a00ddda45032f4e91\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built transformers pathtools\n",
            "Installing collected packages: tokenizers, safetensors, pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, huggingface-hub, gitdb, transformers, GitPython, wandb, accelerate\n",
            "Successfully installed GitPython-3.1.32 accelerate-0.21.0 docker-pycreds-0.4.0 gitdb-4.0.10 huggingface-hub-0.16.4 pathtools-0.1.2 safetensors-0.3.1 sentry-sdk-1.29.2 setproctitle-1.3.2 smmap-5.0.0 tokenizers-0.13.3 transformers-4.32.0.dev0 wandb-0.15.8\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers wandb pandas torch 'transformers[torch]'"
      ],
      "id": 2.7299665331067346e+38
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def load_data(URL):\n",
        "  quotes=pd.read_csv(URL,header=None)\n",
        "  quotes=quotes.fillna('')\n",
        "  return quotes\n",
        "quotes=load_data(\"https://huggingface.co/datasets/Crapp/sadQuotes/raw/main/quotes.csv\")"
      ],
      "metadata": {
        "id": "KPaJT9JD4XLy"
      },
      "id": "KPaJT9JD4XLy",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quote=quotes.iloc[:][1]\n",
        "quote=quote.str.split('.').explode()\n",
        "type(quote)\n",
        "quote=\"\\n\".join(quote)"
      ],
      "metadata": {
        "id": "nqbG6hKN4c8Z"
      },
      "id": "nqbG6hKN4c8Z",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str2file = open(\"quotes.txt\", \"w\")\n",
        "str2file.write(quote)\n",
        "str2file.close()\n",
        "#quote.to_csv(r'quotes.txt', header=None, index=None, sep=' ', mode='w')"
      ],
      "metadata": {
        "id": "5uDErWlSPoVB"
      },
      "id": "5uDErWlSPoVB",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head quotes.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vmS0i-j5Bor",
        "outputId": "02a2e8ba-ec7b-4f4d-a978-990326d0db64"
      },
      "id": "5vmS0i-j5Bor",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is happening in your Mind is not Reality; it is important to differentiate between the two\n",
            "\n",
            "Once you cultivate Equanimity within, every cell in your body will respond by generating Sweetness\n",
            "\n",
            "Life is a limited amount of Time and Energy\n",
            " Let us use it for maximum Impact\n",
            "\n",
            "What is good for the soil is always good for your body because your body is just an embodiment of soil\n",
            "\n",
            "Our intention is to make this Planet into a Temple where everyone walks with a certain Grace and reverence to Life\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import transformers\n",
        "import tqdm\n",
        "MODEL_NAME = 'gpt2'\n",
        "TEXT_CORPUS = 'quotes.txt'\n",
        "DEVICE = 'cuda'\n",
        "TOKEN_ENDOFTEXT = 50256  # '<|endoftext|>\n",
        "BLOCK_LEN = 512"
      ],
      "metadata": {
        "id": "r8TDgP040P8Y"
      },
      "id": "r8TDgP040P8Y",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    model = transformers.GPT2LMHeadModel.from_pretrained(MODEL_NAME)\n",
        "    tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "7DMX4Oi03JBs"
      },
      "id": "7DMX4Oi03JBs",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    model.to(DEVICE)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "djeMzrIy3cHx"
      },
      "id": "djeMzrIy3cHx",
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def break_text_to_pieces(text_path: str, tokenizer: transformers.PreTrainedTokenizer, block_len: int = 512) -> list[str]:\n",
        "    \"\"\"Read a file and convert it to tokenized blocks, edding <|endoftext|> to each block\"\"\"\n",
        "    with open(text_path) as f:\n",
        "        text = f.read()\n",
        "    chunk_len0 = block_len - 1  # Leave space for a TOKEN_ENDOFTEXT\n",
        "    tokens = tokenizer.encode(text)\n",
        "    blocks = []\n",
        "    pos = 0\n",
        "    while pos < len(tokens):\n",
        "        chunk = tokens[pos: pos + chunk_len0]\n",
        "        chunk.append(TOKEN_ENDOFTEXT)\n",
        "        blocks.append(chunk)\n",
        "        pos += chunk_len0\n",
        "\n",
        "    if len(blocks[-1]) < block_len:\n",
        "        del blocks[-1]\n",
        "\n",
        "    return blocks"
      ],
      "metadata": {
        "id": "udXlBYDi33UE"
      },
      "id": "udXlBYDi33UE",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dsets(text_path: str, tokenizer: transformers.PreTrainedTokenizer, block_len: int):\n",
        "    \"\"\"Read the text, prepare the datasets \"\"\"\n",
        "    data = break_text_to_pieces(text_path, tokenizer, block_len)\n",
        "    data_train, data_val = train_val_split(data, 0.1)\n",
        "    return MyDset(data_train), MyDset(data_val)"
      ],
      "metadata": {
        "id": "5pTj2WyB3r9_"
      },
      "id": "5pTj2WyB3r9_",
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_split(data: list[str], ratio: float):\n",
        "    n = len(data)\n",
        "    assert n >= 2\n",
        "    n_val = max(1, int(n * ratio))\n",
        "    return data[n_val:], data[:n_val]"
      ],
      "metadata": {
        "id": "RuRh2TSz694m"
      },
      "id": "RuRh2TSz694m",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDset(torch.utils.data.Dataset):\n",
        "    \"\"\"A custom dataset that serves 1024-token blocks as input_ids == labels\"\"\"\n",
        "    def __init__(self, data: list[list[int]]):\n",
        "        self.data = []\n",
        "        for d in data:\n",
        "            input_ids = torch.tensor(d, dtype=torch.int64)\n",
        "            attention_mask = torch.ones(len(d), dtype=torch.int64)\n",
        "            self.data.append({'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': input_ids})\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        return self.data[idx]\n"
      ],
      "metadata": {
        "id": "P-bgTtKk7Klb"
      },
      "id": "P-bgTtKk7Klb",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    import locale\n",
        "    locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "    dset_train, dset_val = prepare_dsets(TEXT_CORPUS, tokenizer, BLOCK_LEN)\n",
        "    loader_train = torch.utils.data.DataLoader(dset_train, batch_size=1)\n",
        "    loader_val = torch.utils.data.DataLoader(dset_val, batch_size=1)"
      ],
      "metadata": {
        "id": "qWmMRpg93hh1"
      },
      "id": "qWmMRpg93hh1",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one(model: torch.nn.Module, loader: torch.utils.data.DataLoader, optimizer: torch.optim.Optimizer):\n",
        "    \"\"\"Standard PyTorch training, one epoch\"\"\"\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for batch in tqdm.tqdm(loader):\n",
        "        for k, v in batch.items():\n",
        "            batch[k] = v.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['labels'])\n",
        "        # loss, logits, past_key_values\n",
        "        loss = out['loss']\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "    return np.mean(losses)"
      ],
      "metadata": {
        "id": "9uCLuBXK7XkA"
      },
      "id": "9uCLuBXK7XkA",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val_one(model: torch.nn.Module, loader: torch.utils.data.DataLoader):\n",
        "    \"\"\"Standard PyTorch eval, one epoch\"\"\"\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    for batch in tqdm.tqdm(loader):\n",
        "        for k, v in batch.items():\n",
        "            batch[k] = v.to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            out = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['labels'])\n",
        "        # loss, logits, past_key_values\n",
        "        loss = out['loss']\n",
        "        losses.append(loss.item())\n",
        "    return np.mean(losses)"
      ],
      "metadata": {
        "id": "e_lSf87T7Yqs"
      },
      "id": "e_lSf87T7Yqs",
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "m9UQ9IltBW86",
        "outputId": "6da44ee2-ea6b-4de9-b964-47750002fdce"
      },
      "id": "m9UQ9IltBW86",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    project=\"sadGPT\",\n",
        "    config={\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"architecture\": \"gpt2\",\n",
        "    \"dataset\": \"https://huggingface.co/datasets/Crapp/sadQuotes/raw/main/quotes.csv\",\n",
        "    \"epochs\": 20,\n",
        "    })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "9HISqcaaQmXy",
        "outputId": "5589ac0c-755c-4f4b-9293-8263f84f037d"
      },
      "id": "9HISqcaaQmXy",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230806_193253-5zyzho5c</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sadgpt/sadGPT/runs/5zyzho5c' target=\"_blank\">stilted-universe-2</a></strong> to <a href='https://wandb.ai/sadgpt/sadGPT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sadgpt/sadGPT' target=\"_blank\">https://wandb.ai/sadgpt/sadGPT</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sadgpt/sadGPT/runs/5zyzho5c' target=\"_blank\">https://wandb.ai/sadgpt/sadGPT/runs/5zyzho5c</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sadgpt/sadGPT/runs/5zyzho5c?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7edf54f903d0>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(20):\n",
        "        loss_train = train_one(model, loader_train, optimizer)\n",
        "        loss_val = val_one(model, loader_val)\n",
        "        print(f'{epoch} : loss_train={loss_train}, loss_val={loss_val}')\n",
        "        wandb.log({\"loss_train\": loss_train, \"loss_val\": loss_val})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sk45HdZ17S0u",
        "outputId": "4876aace-4f4f-4cd1-f348-2678cc03c40c"
      },
      "id": "Sk45HdZ17S0u",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [00:26<00:00,  5.14it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 18.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 : loss_train=0.11798471010945462, loss_val=5.875938756125314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [00:27<00:00,  4.98it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 19.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : loss_train=0.11066545162487913, loss_val=5.8920718261173795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [00:26<00:00,  5.14it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 20.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 : loss_train=0.1105152759011145, loss_val=5.818116835185459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [00:26<00:00,  5.12it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 19.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 : loss_train=0.11273168915951694, loss_val=5.97877311706543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [00:26<00:00,  5.07it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 20.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 : loss_train=0.10116661519364074, loss_val=6.063339846474784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [00:26<00:00,  5.10it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 19.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 : loss_train=0.10057174577205269, loss_val=6.130635874611991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [00:26<00:00,  5.11it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 19.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 : loss_train=0.10709198848516853, loss_val=6.137974534715925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [00:26<00:00,  5.09it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 19.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 : loss_train=0.10492534209732655, loss_val=6.0036464759281705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [00:26<00:00,  5.09it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 19.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 : loss_train=0.10781721814914987, loss_val=5.948036432266235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [00:26<00:00,  5.10it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 19.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 : loss_train=0.10292802505471088, loss_val=6.065492766244071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [00:26<00:00,  5.10it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 19.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 : loss_train=0.0947672523006245, loss_val=5.894904204777309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [00:26<00:00,  5.09it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 19.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 : loss_train=0.09057616765300433, loss_val=5.903630903788975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [00:26<00:00,  5.08it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 19.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 : loss_train=0.09394439652010246, loss_val=6.159625632422311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [00:26<00:00,  5.09it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 19.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13 : loss_train=0.09549259576532576, loss_val=5.984661476952689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [00:26<00:00,  5.10it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 19.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14 : loss_train=0.0873871274292469, loss_val=6.17333367892674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [00:26<00:00,  5.09it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 19.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15 : loss_train=0.09377681061073585, loss_val=6.156057255608695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [00:26<00:00,  5.09it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 19.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16 : loss_train=0.10323801382824227, loss_val=6.163485527038574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [00:26<00:00,  5.09it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 19.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17 : loss_train=0.0944123996766629, loss_val=6.115964242390224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [00:26<00:00,  5.08it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 19.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18 : loss_train=0.08316223000486692, loss_val=6.0909091745104105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [00:26<00:00,  5.09it/s]\n",
            "100%|██████████| 14/14 [00:00<00:00, 19.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19 : loss_train=0.08470383475500125, loss_val=6.1462615217481344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    if loss_val <= loss_train:\n",
        "        wandb.alert(\n",
        "            title='Validation lower that Train?',\n",
        "            text=f'Val {loss_val} is below the Train losss {loss_train}',\n",
        "        )\n",
        "        print('Alert triggered')"
      ],
      "metadata": {
        "id": "mUDMVqeGYPGD"
      },
      "id": "mUDMVqeGYPGD",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291,
          "referenced_widgets": [
            "56fa2e28d0bd42929a8fb5e8fbc65c59",
            "afee744d2d5e40269d51c696673853ec",
            "6aabbe85c04f435ca2e19315091db34a",
            "4d496f5b4710480c8e88acba0520554f",
            "879e14ff76194219b22a40df94b6c7d7",
            "dd788969d47d44ef818e9c29323dce66",
            "e029b78eb32648a89e63977015687926",
            "16c2495aeab546a0857e5f00b682d4f6"
          ]
        },
        "id": "4NqkGwRpVRia",
        "outputId": "e6c2cb36-f0ef-4f90-e7e0-2f2e730926a0"
      },
      "id": "4NqkGwRpVRia",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56fa2e28d0bd42929a8fb5e8fbc65c59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss_train</td><td>█▇▆▇▅▄▆▅▆▅▃▂▃▃▂▃▅▃▁▁</td></tr><tr><td>loss_val</td><td>▂▂▁▄▆▇▇▅▄▆▃▃█▄███▇▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss_train</td><td>0.0847</td></tr><tr><td>loss_val</td><td>6.14626</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">stilted-universe-2</strong> at: <a href='https://wandb.ai/sadgpt/sadGPT/runs/5zyzho5c' target=\"_blank\">https://wandb.ai/sadgpt/sadGPT/runs/5zyzho5c</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230806_193253-5zyzho5c/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "        model.save_pretrained('./trained_model/')\n",
        "        tokenizer.save_pretrained('./trained_model/')"
      ],
      "metadata": {
        "id": "4Hzd12om_WLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47fd7bf4-7af3-4193-97c1-9f9513845cfd"
      },
      "id": "4Hzd12om_WLl",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./trained_model/tokenizer_config.json',\n",
              " './trained_model/special_tokens_map.json',\n",
              " './trained_model/vocab.json',\n",
              " './trained_model/merges.txt',\n",
              " './trained_model/added_tokens.json',\n",
              " './trained_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    prompt = 'Purpose of Life?'\n",
        "    #prompt = 'Purpose of sex?' #memorized!\n",
        "    batch = tokenizer([prompt], return_tensors='pt')\n",
        "    for k, v in batch.items():\n",
        "        batch[k] = v.to(DEVICE)\n",
        "    out = model.generate(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], max_length=50)\n",
        "    outGen=tokenizer.batch_decode(out.cpu())\n",
        "    print(outGen)\n",
        "    outGenFirst = '. '.join(outGen[0].split('\\n')[:-1])\n",
        "    print(outGenFirst.strip(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6exjpss7_dAU",
        "outputId": "94fc42e9-1bb4-4dcb-e8d3-2917a0b287ef"
      },
      "id": "6exjpss7_dAU",
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Purpose of Life?\\nAre you doing it all the time\\n But if you do it with involvement and pride, it’s a quality of involvement, not an act\\n\\nIn positive exchange, you give whatever you can without caring what']\n",
            ". Are you doing it all the time.  But if you do it with involvement and pride, it’s a quality of involvement, not an act.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": 2.8891853944186117e+38
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "def generate(text):\n",
        "    result = generator(text, max_length=300, num_return_sequences=1)\n",
        "    #result = generator(text, max_length=30, num_return_sequences=1)\n",
        "    return result[0][\"generated_text\"]"
      ],
      "id": 2.8891853944186117e+38
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "rqGA69EBfrnF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "rqGA69EBfrnF",
        "outputId": "67ddefca-2a09-4d02-bd75-52caa13a8429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Purpose of Life? (1993)\\n\\nDangerous to Children, Not Kids(1989)\\n\\nDangerous To Adults, Not Children(1993)\\n\\nDevoted, Kind, Compassionate, Love a Lot(1991) Part 1(1992, 1993, 1994)(1993,1994)\\n\\nDogma Is Harmful, Loving Ourselves. (1991)\\n\\nDevoted, Kind, Compassionate, Love a Lot(1991) Part 2(1992)\\n\\nDevoted, Kind, Compassionate, Love a Lot(1991) Part 3(1992)\\n (1994, 1994)\\n\\nDr. Lacey's Dictionary of Sex, Drugs, and Relationships(1991)\\n\\nDr. Lacey's Dictionary of Sex, Drugs, and Relationships(1991) Part 4(1993)\\n\\nDangerous to Children, Not Kids(1991)\\n\\nDangerous To Adults, Not Children(1993)\\n\\nDeeply Awkward, Kind, Compassionate, Like Love a Lot(1992)\\n\\nDevoted, Kind, Compassionate, Love a Lot(1992) Part 5(1992)\\n\\nDevoted, Kind, Compassionate, Love a Lot(1992) Part 6(1992)\\n\\nDeeply Awkward, Kind, Compassionate, Like Love a Lot(1992) Part 7(1992)\\n\\nDeeply Awkward, Kind, Compassionate\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 128
        }
      ],
      "source": [
        "generate(prompt)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
      }
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "56fa2e28d0bd42929a8fb5e8fbc65c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_afee744d2d5e40269d51c696673853ec",
              "IPY_MODEL_6aabbe85c04f435ca2e19315091db34a"
            ],
            "layout": "IPY_MODEL_4d496f5b4710480c8e88acba0520554f"
          }
        },
        "afee744d2d5e40269d51c696673853ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_879e14ff76194219b22a40df94b6c7d7",
            "placeholder": "​",
            "style": "IPY_MODEL_dd788969d47d44ef818e9c29323dce66",
            "value": "0.001 MB of 0.014 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "6aabbe85c04f435ca2e19315091db34a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e029b78eb32648a89e63977015687926",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16c2495aeab546a0857e5f00b682d4f6",
            "value": 0.08095631803775664
          }
        },
        "4d496f5b4710480c8e88acba0520554f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "879e14ff76194219b22a40df94b6c7d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd788969d47d44ef818e9c29323dce66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e029b78eb32648a89e63977015687926": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16c2495aeab546a0857e5f00b682d4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}